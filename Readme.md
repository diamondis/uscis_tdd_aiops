
# Section 1:	Team Diamond Capabilities:
  
Team Diamond comprised of **Diamond Information Systems**, and our teaming partners, **i3Solutions** and **Harmonia Holdings Group** have extensive experience in defining and architecting data fusion and data analysis technology solutions for Government Agencies and commercial organizations. Our focus has been to invest significant time and research to become experts into the different tools to help automate the fusion of disparate data sources; and to implement tools to provide better data analytics and visualization. 

We will bring the best practices and insights gained from our projects to guide the Department of Homeland Security through all stages to complete the analysis and discovery of the different target data sources. We will also provide guidance to avoid the pitfalls and limitation of more tradition reporting tools. Our teams were one of the first to fuse machine learning (ML) and Natural Language Processing (NLP) technologies into Portal tools to bring significant improvements to the way user can search data for patterns, relationships, and trends.  We have successfully implemented solutions leveraging these solutions and are proposing to bring these proven solutions to the DHS. We also have significant experience with DevOpsSec at agencies such as the U.S. Census Bureau. We have deployed applications on the cloud - AWS, and on-premises. 

Team Diamond has delivered technology projects for many government customers: including the U.S. Army Special Operations Command (USSOCOM), National Security Agency (NSA), the U.S. Army INSCOM, the U.S. Department of Justice (DOJ), National Security Agency (NSA), U.S. Department of Homeland Security (DHS), the U.S. Department of the Treasury (DOT), the U.S. Department of the Interior, Health and Human Services (HHS), U.S. Department of Agriculture, U.S. Patent and Trademark Office, U.S. Census Bureau, Defense Information Systems Agency (DISA), Missile Defense Agency, U.S. Air Force, U.S. Army, U.S. Marine Corps, U.S. Navy and many more.

## 1.1	Proposed Subject Matter Experts / Key Persons:
Our Subject Matter Experts (SMEs), Mr. Anantha Bangalore and Dr. Chul Gwon have extensive and deep experience in the areas of Agile, DevSecOps, Cybersecurity, Artificial Intelligence, and Deep Learning as demonstrated in their profiles shown below.

### 1.1.1	Mr. Anantha Bangalore
**Percipient.ai** 

Mr. Bangalore is the CTO and CISO of percipient.ai and is instrumental in the creation of the DevSecOps platform that is used to build the product Mirage, which is a AI / computer vision product built using deep learning algorithms for DoD and IC communities. The DevSecOps platform supports multiple deployments across multiple environments in a given day. Mirage is a large and complex system with over multiple microservices, each of which is running numerous docker containers. The platform supports deployment to both on-prem appliances as well as to the AWS cloud. Mirage provides facial and object recognition capabilities for full motion video. The CI/CD pipeline is built using tools such as Jira, Github and Jenkins. Automated testing, using cucumber and selenium is tightly integrated into the platform. Tools such as Twistlock, Fortify, BurpSuite and Nessus are integrated for security testing. SonarQube is used to measure code quality as well as code coverage for testing. Mirage is built on top of multiple open source technologies. The ELK stack as well as Cloud Watch and Cloud trail are used to continuously monitor various parameters of every aspect of the system at a granular level. All of these data is captured in influxDB and Graphana is used to visualize the performance metrics of various services and api’s.  The platform supports deployment on GPU based servers as well as CPU servers. Ansible in combination with Terraform and Cloud formation scripts are used for automated provisioning of infrastructure. Mirage uses Kubernetes to rapidly scale based on load.

**DHS ESDO**

Mr. Bangalore was the principal architect of a DevSecOps platform at DHS ESDO. This platform was built primarily to support the build and deployment of a Drupal based Platform as a Service to host and support the web sites and services of various DHS agencies. The Drupal based PaaS supported over 60 million users and was resilient to support sudden surge in load during major weather events such as Hurricane Sandy, when people depended upon information provided by FEMA for support. The system had no down time during such events. The DevSecOps platform was later expanded to support multiple projects (over 20) from many different DHS agencies.  Following are some of the tools (Appendix A) used in this platform

**National Institutes of Health (NIH) – National Library of Medicine (NLM)**

Mr. Bangalore was the primary architect and developer of many Natural Language Processing based systems at the National Library of Medicine (NLM), which is a part of the NIH. He built systems that used a variety of Supervised and Un-supervised algorithms to assist the categorization and search and retrieval of bio-medical information. He was also deeply involved in the design and development of clinical trials.gov, which is built on top of various AI/ML models. He has published many peer review papers in national and international conferences on these topics.

**Tools, Technologies, Programming Languages**

Apache Spark, Apache MxNet, AWS Cloud, AWS Linux, Cassandra, Cucumber, Selenium, Docker, ElasticSearch, Fortify, Github, Terraform, Jira, Jenkins, JUnit, Kibana, Logstash, Maven, Nexus, NumPY, OpenCV, PostgreSQL, Python, OWASP, OpenShift, ReactJS, Selenium, SonarQube, Scala, TensorFlow, Apache JMeter, Apache Tomcat, New Relic, SonarQube, C, C++, Java, JavaScript (React, Angular), Python, AWS, AWS CloudWatch, Ansible, Terraform, VMWare

### 1.1.2	Dr. Chul Gwon
Dr. Chul Gwon received his Ph.D. in Particle Physics in 2003 from Ohio State. He has supported the DoD and the Intelligence Community for over 15 years.  6He has experience developing deep learning solutions for the government and commercially using several open source libraries, including Tensorflow, PyTorch, MxNet.  Along with machine learning expertise, Dr. Gwon is an AWS Certified Solutions Architect Associate. Relevant experience includes the projects shown below.
 
**Analytic Folk**

Dr Gwon developed machine learning solutions in Tensorflow and PyTorch for object detection as well as low-shot learning techniques for classification of images with few samples. Solutions were developed on commercial AWS and C2S. Work was done in support of NGA Technology Directorate.
 
**Clarifai** 

Dr. Gwon served as the research manager for the DC office, supporting commercial efforts as well Project Maven, where he developed state-of-the-art object detection algorithms for EO and IR mid-level ISR full motion video for objects of interest. Models were developed using Tensorflow, and deployed on AWS as well as on-premise. He also led an effort with NVIDIA to port Clarifai models from Tensorflow to TensorRT for faster inference capabilities, and presented his work jointly with Google and NVIDIA at the GTC Conference in San Jose, CA.
 
**Percipient.ai**

Dr. Gwon worked with Silicon Valley scientists to develop object detection and face recognition algorithms using MxNet for processing full motion video in the Mirage system. Solutions were developed for AWS as well as on a hardware appliance. Worked on deployment of the Mirage system, which consisted of Docker containers using MxNet as well as Apache Spark for processing streams from cameras.
 
**SpaceFlight Industries** 

Dr. Gwon developed a reinforcement learning algorithm using Tensorflow for optimizing performance of auto-scaling groups on AWS. He also explored deep NLP solutions using PyTorch for performing a variety of tasks such as text classification and summarization. He created an open-source object detection pipeline using AWS S3, AWS Lambda, and Flask, deployable using AWS CloudFormation. Work was done in support of the NGA Technology Directorate and ODNI’s Advanced Campaign Cell.
 
**Booz Allen** 

Dr. Gwon developed deep learning solutions for object detection for NGA Research Directorate. He also served as the Pod Lead on the contractor side for the Anticipatory Analytics and Geospatial Cyber Research Pods. He developed the Catalyst big data analytics framework and implemented a scalable co-location algorithm using tools in the Hadoop Ecosystem (Spark, Storm, Kafka, Accumulo).
 
**Tools, Technologies, Programming Languages**

Tensorflow, PyTorch, MxNet, Numpy, OpenCV, Pillow, Matplotlib, Hadoop, Spark, Kafka, Accumulo, AWS/C2S, Docker, Databricks, Jupyter, Python, Java, Scala, C++

## 1.2	IT Projects Experience / Capabilities
Team Diamond is providing information on the following projects to demonstrate our experience and capabilities in the scope areas listed in the RFI. The table below shows Team Diamond’s capabilities in all of the AI/ML Technology areas listed in the RFI.






|                                          |
|------------------------------------------|
| ***Programming Languages:***<br><br>**Diamond - Census:** We utilize the following languages: Java, Python, R, C++, C, JavaScript. We supported close to 50 Enterprise Level applications, supporting activities of the Decennial Census. Examples of applications are – Responses from Public, Fraud Detection, HR Management for the Temporary Workforce, Routing of Census Takers, and many others.<br><br>**i3solutions:** We utilize the following languages: MVC, .NET, C#, Java, Python, R, C++, C, JavaScript – Successful implemented over 600 enterprise Level applications, supporting both Government agencies and commercial organizations. Examples of applications are – Data Fusion solutions, ML and NLP based Discovery portals, workflow solutions, Data Analytic systems, contract and proposal system, knowledge management solutions, intelligence dissemination solutions, AI and ML intelligence portals, Data Integration solutions, and much more.<br><br>**Harmonia:** We utilize the following languages: Python, Java, JavaScript, .NET, C#. We supported various organizations within the USDA such as PHIS and FRIO. Ported applications from on premise servers to cloud using Microservices and containers. <br> |
| ***Microservices and Containerized Services Platforms:***<br><br>**Diamond - Census:** We implemented solutions using Docker, AWS Elastic Container Service (ECS), Kubernetes, OpenShift. Supported the creation of new Enterprise Applications such as Responses from Public were architected and build using Docker containers and microservices. They were hosted on AWS GovCloud.<br><br>**i3solutions:** We implemented solutions on both Azure and AWS platforms for numerous Government and Commercial organizations.  These include AI/ML solutions and platforms using Azure microservices and AWS.<br><br>**Harmonia:** We utilize the following tools: Python, C#, Docker, OpenShift. Adopted the U.S. Digital Services (USDS) Playbook principles, including deploying in a flexible hosting environment (OpenShift) that easily ports from on-premises servers to cloud, using microservices. Performed a careful analysis of alternatives for a new technology stack. The choices of Jenkins, Git, Docker, Linux, Python, Django, Postgres, and Selenium were a vast change from FSIS’s legacy .Net/Windows without CI. Introduced new methods of source code management for Git. Examples are rules to branch code when creating a new feature, and other rules to merge conflicts before committing code to Git. We introduced automation into CM consistent with DevOps by requiring all artifacts, including automation scripts, to be put under CM control with versioning via Git. We created automation scripts for all repeatable tasks to reduce manual system administration, with parameterization to maximize the range of tasks the scripts could automate.<br> |
| ***Message Streaming:***<br><br>**Diamond - Census:** We supported the implementation of Kafka for message streaming for ingesting streams of data from multiple disparate sources into a very large Hortonworks data lake.<br><br>**i3solutions:** Developed over 240 different data fusion and import tools to ingest and aggregate numerous open source and disparate knowledge feeds, open source data, and social feeds.  Have implemented solutions to integrate numerous disparate government and military data feeds and OSINT sources.<br> |
| ***CI/CD Pipeline Automation:***<br><br>**Diamond – Census:** We utilize the following: Jenkins, GitHub, Maven, SonarQube, Fortify, Terraform, WebInspect, Cucumber, Selenium, Akamai, JUnit, Ansible, Puppet, LoadRunner, JMeter, Artifactory, Splunk, Docker. We supported the automation of more than 20 large applications such as Responses from Public and HR Management for the Temporary Workforce. These applications were all built using the CI/CD pipeline and were deployed to Amazon GovCloud as well as a Census private data center.<br><br>**i3solutions:** We utilize the following:  GitHub, JIRA, Fortify, Selenium, JUnit, LoadRunner, Splunk and more for pipeline automation.  We have also built custom automation solutions using workflow tools, SharePoint, .NET, Nintex, K2, and more.  We were responsible for integrating all systems with other applications and data sources.<br><br>**Harmonia:** We used the following tools: Git, Capser.JS, Selenium, Jenkins, Docker, OpenShift, Coverage.py. We applied software library automation to maintain shared libraries of web services in Docker containers across our FSIS projects. We configured Jenkins as a quality metrics dashboard to display graphs with drilldown of which builds succeeded or failed, trends in number of potential code quality findings, and trends in defect and code coverage (using Coverage.py) metrics. Our automated CICD pipeline takes only 19 minutes from code commit to deployment (with just 14 seconds for deployment), executing 351 automated tests that exercise 100% of all files and classes and 90% of all code lines. Manual methods would have taken hours. We maintain 99.9%+ uptime in our pipeline. <br> |
| ***AI/ML Platforms and Integration:***<br><br>**Daimond - Census:** We have implemented solutions using: MxNet, TensorFlow, R Studio. We supported AI Integration for the Fraud Detection application, which was designed to detect fraudulent responses from the census data collected. The application used a variety of open data sources including social media platforms such as facebook and twitter to monitor information, in detecting fraud.<br><br>**i3solutions:** We have implemented solutions using: R, Studio, .NET, C#, Java, JavaScript, and numerous open source platforms to build AL and ML solutions.  We have also implemented solutions using IBM Watson, WEX, Azure and SQL services.  We also built our own Data Fusion portal that includes over 240 pre-built connectors.  The platform automatically tags incoming data and identifies patterns and relationships in the data.<br> |
| ***Alerting and Monitoring:***<br><br>**Diamond – Census:** We used the following: Splunk, CloudWatch, CloudTrails, Nagios, SolarWinds, ElasticSearch, ELK Stack. These tools were configured to monitor and alert across all aspects of the Census enterprise, including the private data center as well as the AWS cloud. This monitored all applications, infrastructure, networks and platforms. <br><br>**i3solutions:** We have built tools to monitor and capture alerts and message across numerous systems and data sources.  We use AI and ML tools for predictive analysis of the data.  We can ingest multiple message streams, auto-tag the data, perform analysis, and identify patterns and relationships in the data.<br> |
| ***Implementation of Shift-Left Strategy and Up-front Threat Assessment Models:***<br><br>**Diamond – Census:** We used the following: Fortify, CheckMarx, WebInspect. Security was integrated tightly into the DevOps process from the ground up. Security was involved in every aspect of systems development starting from design and architecture, to coding, all the way through deployment. Security testing was performed early and often, which not only helped the applications be more secure, it also led to a faster ATO upon deployment. <br> |
| ***Perform Platform Level Threat Assessment:***<br><br>**Diamond – Census:** We used the following tools: Kali Linux, Metasploit. These and other tools were used to monitor variety of threats across the Census enterprise. Security team used multiple offensive and defensive tools to perform threat assessments. Included review of open source databases, and using frameworks such as Kali Linux to perform penetration testing of various services to check for any new vulnerabilities, and provide that input back to the development team for remediation.<br> |
| ***Areas of Automating:***<br><br>**i3solutions:** Leveraged workflow tools to automate data collection, business processes, issue resolution, assignments, and tracking.  Used ML tools to identify patterns and recurring issues and automatically route issues based on past issues.  Leveraged ML tools to adaptively route issues to the correct resources based on pattern recognition. We have built workflow and process automation solutions using workflow platforms and open source tools.<br><br>**Harmonia:** We created automation scripts for all repeatable tasks to reduce manual system administration, with parameterization to maximize the range of tasks the scripts could automate. We implemented fully automated builds. When code was committed to Jenkins, a build was scheduled on demand followed by code style/quality analysis with Flake8. We implemented automated tests in Casper.JS and Selenium. Through performance testing we pinpointed the slowest responding user pages and optimized them, for example introducing Postgres materialized views to cut administrative page response times by 82%, and administrative page times from 10-11 seconds down to 1.5 seconds.<br> |
| ***Demonstration of Analytics Based on Big Data Lakes:***<br><br>**Diamond – Census:** We have used tools such as: Kafka, Tableau, SAS, R Studio, Hortonworks. Supported the creation of an enterprise wide data lake to collect data from various disparate sources, before and after the Census, to analyze and provide information to Congress and OMB to make budget and resource allocations.<br><br>**i3solutions:** We have implemented data analysis solutions using SQL Server, SSAS, Azure, Dundas, Tableau, PowerBI, WEX, Watson, and open source solutions.  Our solution ingests multiple data sources and provide data visualization tools for self-service based analysis tools.  We also implement NLP tools to provide better tools for search and discovery of the data.<br> |
| ***Working with Disparate Data Sources for a Predictive Analysis:***<br><br>**Diamond – Census:** Supported the utilization of data from previous Census to determine which communities would have a lower response rate, so that census takers could be routed to those areas to facilitate the collection of Census. data.<br><br>**i3solutions:**  Utilize data integration and aggregation tools to import and merge disparate data sources.  Can use open source tools like MySQL and other open source databases.  Can also use tools included in Microsoft Azure and AWS to build integration tool to import different data sources.  We also have over 240 pre-built data integrations API’s in the JCIP Data Fusion tool to import and integrate data from disparate data sources, open source data feeds, and social media data sources.<br> |
| ***Implementing Cloud Best Practices Using AI Predictive*** Analysis:<br><br>**i3solutions:**  We use MI and NLP tools to analyze a wide variety of issues to auto-apply metadata to all tickets to identify patterns and relationships. Use ML and NLP tools to build workflows to analyze new tickets and apply past history and resolutions stored in the system.  We have implemented NLP tools and Azure tools to allow users to ask questions in natural language and have the system predict possible solutions.<br> |
| ***Formed a Technical Team as First Point of Contact to Address and Resolve Tickets:***<br><br>**Diamond – Census:** Supported the creation of a large team that used ServiceNow, a large team, that included a sub-team of Technical Architects across various programs. This team were the primary Point of Contact for all technical issues and coordinated with the team leads across various TI programs to support the resolution of technical issues related to both design or architecture issues, or production problems.<br><br>**i3solutions:** We have provided first point of contact Technical and applications support services for both Government and Commercial customers.  We have supported databases, applications, websites, SharePoint systems, data integrations, discovery and search systems, workflow solutions and more.  We help with issues resolutions, end-user training, knowledge transfer, recurring issue identification, knowledge base creation, and more.<br> |
| ***Experience with DevOps Alerting and Monitoring:***<br><br>**Diamond – Census:** Splunk, CloudWatch, CloudTrails, Nagios, SolarWinds, ElasticSearch – These tools were configured to monitor and alert across all aspects of the Census enterprise, including the private data center as well as the AWS cloud. This monitored all applications, infrastructure, networks and platforms.<br><br>**i3solutions:** We have implemented DevOps alerting and monitoring tools in both Azure and AWS.  Our solutions have monitored data base health, system performance, data ingest monitoring, and more.<br> |
| ***Demonstration of Analytics Based on Service Desk Tickets:***<br><br>**i3solutions:** We have implemented solutions using ML and NLP to analyze service desk solutions to auto-tag the tickets and to build a knowledge base.  The ML and NLP tools are used to identify patterns and relationships to provide better recommendations for future issues.  The ML and NLP tools are also used to perform predictive analysis to provide intelligence assignment and routing of issues and recurring patterns.  The tools also provide ML based dynamic search for better results based on patterns.<br> |
| ***Implementing intelligent Tier 3 Ops routing system:***<br><br>**Diamond – Census:** We have supported Tiers 1, 2, and 3 Cybersecurity support, where we route responds through ServiceNow, and respond to tickets 24X7. Our personnel are involved in the SOC and NOC, analyzing various events, and providing resolution and remediation. We have utilized this expertise to support the implementation of an intelligent service escalation process.<br> |






### 1.2.1	Diamond Information Systems – U.S. Census Bureau, 2020 Census
Diamond is supporting the Systems Engineering and Integration (SE&I) group at the U.S. Census Bureau in support of the 2020 Census. The SE&I group is the technical arm of the 2020 Census Program and is responsible for the architecture, the Project and Capability requirements, and the overall integration of systems leading up to all 2020 Census Tests and the 2020 Census. Diamond’s support included the following:
* Support the establishing, designing, governing and maintaining the 2020 Census program initial physical and logical architecture, leveraging the Census Bureau’s enterprise architecture to assure that component systems designs are consistent with mandated standards and that they are designed to inter-operate as required.
*	Supporting the requirements development, management and governance process to assure that operational requirements (and constraints) are fully understood and translated into technical requirements.
* Leveraging a modular open system design to allow for necessary evolution of requirements and expected technology refresh opportunities.
* 	Support establishing a technical integration process, plan and governance approach to assure that separately developed systems can and do operate cooperatively, and are consistent with the concept of operations.
* 	Support the establishment of an Integration & Test function in support of conducting cross segment, end-to-end, and performance testing for the systems in support of the 2020 Census and Census Tests leading up to it. Ensure successful management of interfaces both internal and external. 
* 	Support establishing a systems engineering and integration function in support of the Decennial Census Management Division.
* 	Migrate multiple applications into census provided DevOps environments, either cloud or data-center based.
* 	Work closely with application teams to ensure compliance with High Availability and Disaster Recovery related concept of operations.
* 	Automate workflows through scripting or other technologies such as Ansible or Puppet.
* 	Maintain and administer configuration systems such as Enterprise GitHub, Jenkins and Artifactory.


### 1.2.2	i3Solutions – U.S. Army Special Operations Command, Joint Collaboration Intelligence Platform (JCIP)
Team Diamond member, i3Solutions developed a Knowledge Management and ML-based Search Portal to aggregate large amounts of intelligence data from both secured and open-source data sources. The Data-Fusion portal provides AI/ML based search and discovery tools with predictive results, natural-language querying, pattern recognition, metadata auto-tagging, and relationship mapping. The Data Fusion Portal provides a system that is not only linked with other databases but can also be linked into any civilian sources, receive live feeds, and linked to all Interagency databases in order to synchronize effort across the whole organization.  JCIP combines data fusion with advanced algorithms to create a deep search capability that is specific to the mission or user. Sorting through massive amount of data and generating only the useful information and identifying relationships is what JCIP does.   

JCIP blends cognitive computing tools with advanced analytics and automated workflow capabilities to help enhance, scale, and accelerate human expertise and analysis. By integrating distinctive capabilities and technologies into a ‘single pane of glass’, JCIP enables mission leaders, analysts, and operations to have a holistic view of their environment.  This system aggregates multiple data bases with any civilian sources, incoming live feeds and all Interagency databases in order to synchronize efforts across the whole organizations and governments. This data fusion strategy saves valuable man-hours and allows analysts focus on analyzing data and leaders to focus on the task of decision making based on the analyzed data.  JCIP combines powerful analytical tools to help leaders with advanced critical decision making based on the most up-to-date relevant information available.

This solution contains an AI-based Enterprise Data Service (EDS) that is responsible for analyzing the data being ingested and comparing the data to historical data sets and archives. The EDS also utilizes Natural Language Processing (NLP) technology and ML to perform Link Analysis, Prediction, Trending, and Pattern matching.  These processes allow our system to identify relationships and patterns in the data that can later be visual displayed and searched.  The analyze data is stored along with the metadata and analysis to be searched and analyzed using our dynamic Portal and Search interface. 

JCIP has been deployed internally on the on premises networks including NIPR and SIPR.  The solution has also been deployed on AWS Cloud servers and Microsoft Azure. It is currently deployed in a production environment on both the NIPRNET and SIPRNET networks at the US Army – Special Operations Command.  The platform is also installed at the National Security Agency and other DoD Facilities. JCIP is built using Java, JavaScript, .NET, C#, R, Python, BootStrap, My SQL, WEX, SOLR, SPSS, ESRI, etc.

JCIP was developed using both Machine-Learning (ML) and Natural Language Processing (NLP) components built directly into the solution. The Ingest process leverages both ML and NLP components to import the data, auto-tag all incoming data, apply predictive analytics, and identify relationships in the data.  The Searching tools using both ML and NLP to provide data maps, relationship charts, trends, and dynamic results.

#### 1.2.3	Harmonia – U.S. Department of Agriculture
Team Diamond member, Harmonia spearheaded the switch-over at FSIS from Waterfall development (using manual builds, manual configuration management (CM), and proprietary development stacks) to modern Agile /DevSecOps practices. Further they architected, set up, and matured a continuous integration/delivery (CICD) pipeline (using Jenkins, Maven, Ant, Nexus, SonarQube, Review Board, etc.) with CM and an interface to a CM database (CMDB). Harmonia adopted the U.S. Digital Services (USDS) Playbook principles, including deploying in a flexible hosting environment (OpenShift) that easily ports from on-premises servers to cloud, using microservices. Harmonia performed a careful analysis of alternatives for a new technology stack. The choices of Jenkins, Git, Docker, Linux, Python, Django, Postgres, and Selenium were a vast change from FSIS’s legacy .Net/Windows without CI. 

Harmonia introduced new methods of source code management for Git. Examples are rules to branch code when creating a new feature, and other rules to merge conflicts before committing code to Git. We introduced automation into CM consistent with DevSecOps by requiring all artifacts, including automation scripts, to be put under CM control with versioning via Git. We created automation scripts for all repeatable tasks to reduce manual system administration, with parameterization to maximize the range of tasks the scripts could automate. We implemented fully automated builds. When code was committed to Jenkins, a build was scheduled on demand followed by code style/quality analysis with Flake8. We implemented automated tests in Casper.JS and Selenium. Through performance testing we pinpointed the slowest responding user pages and optimized them, for example introducing Postgres materialized views to cut administrative page response times by 82%, and administrative page times from 10-11 seconds down to 1.5 seconds.

Harmonia applied software library automation to maintain shared libraries of web services in Docker containers across our FSIS projects. We configured Jenkins as a quality metrics dashboard to display graphs with drilldown of which builds succeeded or failed, trends in number of potential code quality findings, and trends in defect and code coverage (using Coverage.py) metrics. Our automated CICD pipeline takes only 19 minutes from code commit to deployment (with just 14 seconds for deployment), executing 351 automated tests that exercise 100% of all files and classes and 90% of all code lines. Manual methods would have taken hours. We maintain 99.9%+ uptime in our pipeline.

We used OpenShift Origin for off-site development, paying to train our staff on OpenShift. Harmonia is now assisting USDA in installing OpenShift Enterprise. We give FSIS staff training support via on-line walkthroughs on configuring/administering OpenShift, since FSIS staff are new to OpenShift and CICD.
